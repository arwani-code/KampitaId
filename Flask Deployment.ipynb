{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "76cd1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask, os, io, h5py\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.restoration import (denoise_wavelet, estimate_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "84b401ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Source</th>\n",
       "      <th>Net</th>\n",
       "      <th>Station_Latitude</th>\n",
       "      <th>Station_Longitude</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Azimuth</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Station Name</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>Station_Elevation</th>\n",
       "      <th>Station_Depth</th>\n",
       "      <th>Earthquake_Latitude</th>\n",
       "      <th>Earthquake_Longitude</th>\n",
       "      <th>Earthquake_Depth</th>\n",
       "      <th>Earthquake_Station_Distance</th>\n",
       "      <th>Back_Azimuth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCO</td>\n",
       "      <td>IRISDMC</td>\n",
       "      <td>II</td>\n",
       "      <td>-12.1901</td>\n",
       "      <td>96.8349</td>\n",
       "      <td>8.622234</td>\n",
       "      <td>-143.996826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>West Island, Cocos (Keeling) Islands</td>\n",
       "      <td>2022-05-16T18:50:28.019538Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.799999</td>\n",
       "      <td>-5.245</td>\n",
       "      <td>102.007698</td>\n",
       "      <td>23.0</td>\n",
       "      <td>954.800049</td>\n",
       "      <td>36.965694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KAPI</td>\n",
       "      <td>IRISDMC</td>\n",
       "      <td>II</td>\n",
       "      <td>-5.0142</td>\n",
       "      <td>119.7517</td>\n",
       "      <td>17.673860</td>\n",
       "      <td>90.057363</td>\n",
       "      <td>300.0</td>\n",
       "      <td>Kappang, Sulawesi, Indonesia</td>\n",
       "      <td>2022-05-16T18:52:29.019538Z</td>\n",
       "      <td>300.0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>-5.245</td>\n",
       "      <td>102.007698</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1965.260376</td>\n",
       "      <td>268.468445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MBWA</td>\n",
       "      <td>IRISDMC</td>\n",
       "      <td>IU</td>\n",
       "      <td>-21.1590</td>\n",
       "      <td>119.7313</td>\n",
       "      <td>23.422910</td>\n",
       "      <td>134.423008</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Marble Bar, Western Australia</td>\n",
       "      <td>2022-05-16T18:53:32.019538Z</td>\n",
       "      <td>93.0</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>-5.245</td>\n",
       "      <td>102.007698</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2597.827881</td>\n",
       "      <td>310.139557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHTO</td>\n",
       "      <td>IRISDMC</td>\n",
       "      <td>IU</td>\n",
       "      <td>18.8141</td>\n",
       "      <td>98.9443</td>\n",
       "      <td>24.247711</td>\n",
       "      <td>-7.075346</td>\n",
       "      <td>420.0</td>\n",
       "      <td>Chiang Mai, Thailand</td>\n",
       "      <td>2022-05-16T18:53:40.019538Z</td>\n",
       "      <td>320.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>-5.245</td>\n",
       "      <td>102.007698</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2679.332520</td>\n",
       "      <td>172.510071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DAV</td>\n",
       "      <td>IRISDMC</td>\n",
       "      <td>IU</td>\n",
       "      <td>7.0697</td>\n",
       "      <td>125.5791</td>\n",
       "      <td>26.551312</td>\n",
       "      <td>62.599605</td>\n",
       "      <td>151.0</td>\n",
       "      <td>Davao, Philippines</td>\n",
       "      <td>2022-05-16T18:54:01.019539Z</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.245</td>\n",
       "      <td>102.007698</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2948.098145</td>\n",
       "      <td>243.135620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station   Source Net  Station_Latitude  Station_Longitude   Distance  \\\n",
       "0    COCO  IRISDMC  II          -12.1901            96.8349   8.622234   \n",
       "1    KAPI  IRISDMC  II           -5.0142           119.7517  17.673860   \n",
       "2    MBWA  IRISDMC  IU          -21.1590           119.7313  23.422910   \n",
       "3    CHTO  IRISDMC  IU           18.8141            98.9443  24.247711   \n",
       "4     DAV  IRISDMC  IU            7.0697           125.5791  26.551312   \n",
       "\n",
       "      Azimuth  Elevation                          Station Name  \\\n",
       "0 -143.996826        1.0  West Island, Cocos (Keeling) Islands   \n",
       "1   90.057363      300.0          Kappang, Sulawesi, Indonesia   \n",
       "2  134.423008      190.0         Marble Bar, Western Australia   \n",
       "3   -7.075346      420.0                  Chiang Mai, Thailand   \n",
       "4   62.599605      151.0                    Davao, Philippines   \n",
       "\n",
       "                    Start_Time  Station_Elevation  Station_Depth  \\\n",
       "0  2022-05-16T18:50:28.019538Z                1.0      44.799999   \n",
       "1  2022-05-16T18:52:29.019538Z              300.0      61.000000   \n",
       "2  2022-05-16T18:53:32.019538Z               93.0      97.000000   \n",
       "3  2022-05-16T18:53:40.019538Z              320.0     100.000000   \n",
       "4  2022-05-16T18:54:01.019539Z              150.0       1.000000   \n",
       "\n",
       "   Earthquake_Latitude  Earthquake_Longitude  Earthquake_Depth  \\\n",
       "0               -5.245            102.007698              23.0   \n",
       "1               -5.245            102.007698              23.0   \n",
       "2               -5.245            102.007698              23.0   \n",
       "3               -5.245            102.007698              23.0   \n",
       "4               -5.245            102.007698              23.0   \n",
       "\n",
       "   Earthquake_Station_Distance  Back_Azimuth  \n",
       "0                   954.800049     36.965694  \n",
       "1                  1965.260376    268.468445  \n",
       "2                  2597.827881    310.139557  \n",
       "3                  2679.332520    172.510071  \n",
       "4                  2948.098145    243.135620  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_csv('data_temp.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4180239c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_station = {}\n",
    "for idx_ in range(len(metadata)):\n",
    "    each_station = {}\n",
    "    station_ = metadata.loc[idx_, 'Station']\n",
    "    station_location_ = metadata.loc[idx_, 'Station Name']\n",
    "    lat_ = metadata.loc[idx_, 'Station_Latitude']\n",
    "    long_ = metadata.loc[idx_, 'Station_Longitude']\n",
    "    elevation_ = metadata.loc[idx_, 'Elevation']\n",
    "    \n",
    "    each_station.update({\n",
    "        'Station':station_,\n",
    "        'Station Location':station_location_,\n",
    "        'Latitude':lat_,\n",
    "        'Longitude':long_,\n",
    "        'Elevation':elevation_\n",
    "    })\n",
    "    data_station.update({f'Station {idx_+1}':each_station})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012bf760",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb40525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app 'Earthquake Model Deployment' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8080 (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [11/Jun/2022 21:24:40] \"GET /station/ HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "#create an instance of Flask\n",
    "app = flask.Flask('Earthquake Model Deployment')\n",
    "app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"Halo dunia tipu tipu!\"\n",
    "\n",
    "@app.route('/station/')\n",
    "def channel_station():\n",
    "    metadata = pd.read_csv('data_temp.csv')\n",
    "    data_station = {}\n",
    "    for idx_ in range(len(metadata)):\n",
    "        each_station = {}\n",
    "        station_ = metadata.loc[idx_, 'Station']\n",
    "        station_location_ = metadata.loc[idx_, 'Station Name']\n",
    "        lat_ = metadata.loc[idx_, 'Station_Latitude']\n",
    "        long_ = metadata.loc[idx_, 'Station_Longitude']\n",
    "        elevation_ = metadata.loc[idx_, 'Elevation']\n",
    "\n",
    "        each_station.update({\n",
    "            'Station':station_,\n",
    "            'Station Location':station_location_,\n",
    "            'Latitude':lat_,\n",
    "            'Longitude':long_,\n",
    "            'Elevation':elevation_\n",
    "        })\n",
    "        data_station.update({f'Station {idx_+1}':each_station})\n",
    "    return flask.jsonify(data_station)\n",
    "\n",
    "\n",
    "app.run(debug=False, port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f270e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD SAVEDMODEL ===\n",
    "\n",
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.precision_fn = tf.keras.metrics.Precision(thresholds=0.5)\n",
    "        self.recall_fn = tf.keras.metrics.Recall(thresholds=0.5)\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        self.f1.assign(2 *((p*r)/(p + r + 1e-6)))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision_fn.reset_states()\n",
    "        self.recall_fn.reset_states()\n",
    "        self.f1.assign(0)\n",
    "\n",
    "PATH = 'C://Users/Zhafran/Documents/Data Science/BANGKIT - Capstone - Earthquake/Model Checkpoint/v1.1 (P-Wave Final)'\n",
    "load_model = tf.keras.models.load_model(PATH, custom_objects={'F1_Score':F1_Score,\n",
    "                                                              'loss':tfa.losses.SigmoidFocalCrossEntropy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "166548ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenoiseWavelet(data, type='BayesShrink'):\n",
    "    def BayesShrink():\n",
    "        im_bayes = denoise_wavelet(np.array(data), convert2ycbcr=True, multichannel=True,\n",
    "                                  method='BayesShrink', mode='soft', \n",
    "                                  rescale_sigma=True, wavelet_levels=4)\n",
    "        return im_bayes\n",
    "    \n",
    "    def VisuShrink():\n",
    "        sigma_est = estimate_sigma(np.array(data), multichannel=True, average_sigmas=True)\n",
    "        im_visu = denoise_wavelet(np.array(img), convert2ycbcr=True, multichannel=True,\n",
    "                                  method='VisuShrink', mode='soft', wavelet_levels=4,\n",
    "                                  sigma=sigma_est, rescale_sigma=True)\n",
    "        \n",
    "        return im_visu\n",
    "    \n",
    "    if type=='BayesShrink':\n",
    "        return BayesShrink()\n",
    "    elif type=='VisuShrink':\n",
    "        return VisuShrink()\n",
    "\n",
    "def create_feature(data_feature):\n",
    "    rs = []\n",
    "#     data_l = get_waveform(data_feature)\n",
    "    data_denoise = DenoiseWavelet(data_feature, type='BayesShrink')\n",
    "#     print(f'data denoise shape: {data_denoise.shape}')\n",
    "    dt = tf.keras.utils.timeseries_dataset_from_array(data=data_denoise, targets=None,\n",
    "                                                          sequence_length=100, sequence_stride=20,\n",
    "                                                          shuffle=False)\n",
    "    for i in dt:\n",
    "        rs.append(i)\n",
    "        \n",
    "    rs = tf.stack(rs)\n",
    "    feature_rs = tf.data.Dataset.from_tensor_slices(rs)\n",
    "    feature_rs = feature_rs.cache().batch(56).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return feature_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1705d86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "511ea128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, batch_size):\n",
    "        self.x = x_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c9b1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict_p(arr, threshold=.5, types='Highest'):\n",
    "    arr = arr.reshape(-1)\n",
    "    \n",
    "    if types=='Highest':\n",
    "        if np.max(arr)>=threshold:\n",
    "            return np.argmax(arr)*20+275\n",
    "        else:\n",
    "            return -1\n",
    "    elif types=='Early':\n",
    "        for i, p_prob in enumerate(arr):\n",
    "            if p_prob>=threshold:\n",
    "                return i*20+275\n",
    "        else:\n",
    "            return -1\n",
    "    elif types=='Late':\n",
    "        i_thres = None\n",
    "        for i, p_prob in enumerate(arr):\n",
    "            if p_prob>=threshold:\n",
    "                i_thres = i\n",
    "        if i_thres!=None:\n",
    "            return i_thres*20+275\n",
    "        else:\n",
    "            return -1\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2cabffd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([216.92195, 202.59862, 376.27274, ..., 364.9865 , 547.75824,\n",
       "       430.6273 ], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ = np.mean(X[1, :, 0])\n",
    "X[1, :, 0]-mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59500c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3a27ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 180000, 3)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.load('C://Users/Zhafran/Documents/Data Science/BANGKIT - Capstone - Earthquake/data_wavelength (1).npz')['arr_0']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6c5b0070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhafran\\AppData\\Local\\Temp/ipykernel_8920/1413613744.py:3: FutureWarning: `multichannel` is a deprecated argument name for `denoise_wavelet`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  im_bayes = denoise_wavelet(np.array(data), convert2ycbcr=True, multichannel=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# X = np.load(io.BytesIO(data))['arr_0']\n",
    "index_ = 2\n",
    "print(X[index_].shape)\n",
    "# data_pred = create_feature(X[index_])\n",
    "\n",
    "for i in range(180000//1200):\n",
    "    start_, end_ = 0, 1200\n",
    "    data_pred = create_feature(X[index_, start_:end_, :])\n",
    "    y_pred = load_model.predict(data_pred)\n",
    "    \n",
    "    high_ = get_predict_p(y_pred, types='Highest')\n",
    "    early_ = get_predict_p(y_pred, types='Early')\n",
    "    late_ = get_predict_p(y_pred, types='Late')\n",
    "    \n",
    "    if (high_ and early_ and late_) == -1:\n",
    "        start_+=1200\n",
    "        end_+=1200\n",
    "        continue\n",
    "    \n",
    "    print(f'Epochs: {i+1}')\n",
    "    print(f'High Probability : {high_} Second')\n",
    "    print(f'Early Probability: {early_} Second')\n",
    "    print(f'Late Probability : {late_} Second\\n')\n",
    "    \n",
    "    start_+=1200\n",
    "    end_+=1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa53be52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ff65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d47cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e491404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "BASE_PATH = 'C://Users/Zhafran/Documents/Data Science/BANGKIT - Capstone - Earthquake/Keys/Cloud Storage'\n",
    "PATH = BASE_PATH+'/bangkit-351503-314e5d9c4252.json'\n",
    "credentials = service_account.Credentials.from_service_account_file(PATH)\n",
    "\n",
    "client = storage.Client(credentials=credentials)\n",
    "\n",
    "# Retrieve an existing bucket\n",
    "# https://console.cloud.google.com/storage/browser/[bucket-id]/\n",
    "bucket = client.get_bucket('data-gempa')\n",
    "\n",
    "# Then do other things...\n",
    "blob = bucket.get_blob('data_wavelength.npz')\n",
    "data = blob.download_as_string()\n",
    "# df = pd.read_csv(io.BytesIO(data))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72670132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b81993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  80.28691  ,   15.379599 ,  -42.924072 ],\n",
       "       [ 100.01992  ,   -3.0439146,  -66.021286 ],\n",
       "       [  97.994774 ,  -22.929815 ,  -66.9469   ],\n",
       "       ...,\n",
       "       [-143.53304  ,  101.31471  ,   31.710686 ],\n",
       "       [ -71.961945 ,   64.44231  ,   25.03955  ],\n",
       "       [  -3.2141392,   31.379045 ,    3.169337 ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(io.BytesIO(data))['arr_0'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84085db5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8920/1495888495.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'arr_0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_feature' is not defined"
     ]
    }
   ],
   "source": [
    "data_pred = create_feature(np.load(io.BytesIO(data))['arr_0'][0])\n",
    "data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd73f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed58ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594e8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37123341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777124d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3290455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3709754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a3c41b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca63375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27483423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4c9b7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_waveform(trace_name):\n",
    "    '''\n",
    "    Kolom 1: East-West Channel\n",
    "    Kolom 2: North-South Channel\n",
    "    Kolom 3: Z (Vertical) Channel\n",
    "    '''\n",
    "    filename = \"merge.hdf5\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        data = f.get('data/'+trace_name)\n",
    "        data = np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "90349870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (7,11,13,14,15,18,19,20,21,22,24,25,26,30,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network_code</th>\n",
       "      <th>receiver_code</th>\n",
       "      <th>receiver_type</th>\n",
       "      <th>receiver_latitude</th>\n",
       "      <th>receiver_longitude</th>\n",
       "      <th>receiver_elevation_m</th>\n",
       "      <th>p_arrival_sample</th>\n",
       "      <th>p_status</th>\n",
       "      <th>p_weight</th>\n",
       "      <th>p_travel_sec</th>\n",
       "      <th>...</th>\n",
       "      <th>source_magnitude_author</th>\n",
       "      <th>source_mechanism_strike_dip_rake</th>\n",
       "      <th>source_distance_deg</th>\n",
       "      <th>source_distance_km</th>\n",
       "      <th>back_azimuth_deg</th>\n",
       "      <th>snr_db</th>\n",
       "      <th>coda_end_sample</th>\n",
       "      <th>trace_start_time</th>\n",
       "      <th>trace_category</th>\n",
       "      <th>trace_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>HH</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-10-21 05:55:00</td>\n",
       "      <td>noise</td>\n",
       "      <td>109C.TA_201510210555_NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>HH</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-06 14:50:00</td>\n",
       "      <td>noise</td>\n",
       "      <td>109C.TA_201511061450_NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>HH</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-07 02:20:00</td>\n",
       "      <td>noise</td>\n",
       "      <td>109C.TA_201511070220_NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>HH</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-14 05:15:00</td>\n",
       "      <td>noise</td>\n",
       "      <td>109C.TA_201511140515_NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TA</td>\n",
       "      <td>109C</td>\n",
       "      <td>HH</td>\n",
       "      <td>32.8889</td>\n",
       "      <td>-117.1051</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-12-25 18:50:00</td>\n",
       "      <td>noise</td>\n",
       "      <td>109C.TA_201512251850_NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  network_code receiver_code receiver_type  receiver_latitude  \\\n",
       "0           TA          109C            HH            32.8889   \n",
       "1           TA          109C            HH            32.8889   \n",
       "2           TA          109C            HH            32.8889   \n",
       "3           TA          109C            HH            32.8889   \n",
       "4           TA          109C            HH            32.8889   \n",
       "\n",
       "   receiver_longitude  receiver_elevation_m  p_arrival_sample p_status  \\\n",
       "0           -117.1051                 150.0               NaN      NaN   \n",
       "1           -117.1051                 150.0               NaN      NaN   \n",
       "2           -117.1051                 150.0               NaN      NaN   \n",
       "3           -117.1051                 150.0               NaN      NaN   \n",
       "4           -117.1051                 150.0               NaN      NaN   \n",
       "\n",
       "   p_weight  p_travel_sec  ...  source_magnitude_author  \\\n",
       "0       NaN           NaN  ...                      NaN   \n",
       "1       NaN           NaN  ...                      NaN   \n",
       "2       NaN           NaN  ...                      NaN   \n",
       "3       NaN           NaN  ...                      NaN   \n",
       "4       NaN           NaN  ...                      NaN   \n",
       "\n",
       "  source_mechanism_strike_dip_rake  source_distance_deg source_distance_km  \\\n",
       "0                              NaN                  NaN                NaN   \n",
       "1                              NaN                  NaN                NaN   \n",
       "2                              NaN                  NaN                NaN   \n",
       "3                              NaN                  NaN                NaN   \n",
       "4                              NaN                  NaN                NaN   \n",
       "\n",
       "  back_azimuth_deg snr_db  coda_end_sample     trace_start_time  \\\n",
       "0              NaN    NaN              NaN  2015-10-21 05:55:00   \n",
       "1              NaN    NaN              NaN  2015-11-06 14:50:00   \n",
       "2              NaN    NaN              NaN  2015-11-07 02:20:00   \n",
       "3              NaN    NaN              NaN  2015-11-14 05:15:00   \n",
       "4              NaN    NaN              NaN  2015-12-25 18:50:00   \n",
       "\n",
       "  trace_category               trace_name  \n",
       "0          noise  109C.TA_201510210555_NO  \n",
       "1          noise  109C.TA_201511061450_NO  \n",
       "2          noise  109C.TA_201511070220_NO  \n",
       "3          noise  109C.TA_201511140515_NO  \n",
       "4          noise  109C.TA_201512251850_NO  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaaa = pd.read_csv('merge.csv')\n",
    "aaaa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "976fe1e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352.21976"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbbb = get_waveform(aaaa.loc[994927, 'trace_name'])\n",
    "np.max(bbbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676d77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
